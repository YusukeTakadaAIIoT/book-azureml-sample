{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11章 基盤モデルとモデルカタログ ファインチューニングデータセット作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "必要なパッケージをimportします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from datasets.load import load_dataset\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.env`から環境変数をロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/yahoojapan/JGLUE/tree/main/datasets/jsts-v1.1\n",
    "\n",
    "本ノートブックではJSTSデータセットのうちtrain-v1.1.jsonを使用します。\n",
    "\n",
    "JSTSは、STS（意味テキスト類似性）データセットの日本語版です。STSは文のペアの意味的な類似性を推定するタスクです。JSTSおよび以下で説明するJNLIの文は日本語版のMS COCOキャプションデータセットおよびYJキャプションデータセット（Miyazaki and Shimizu, 2016）から抽出されています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'train-v1.1.json'\n",
    "df = pd.read_json(file_path, lines=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "システムプロンプトを定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"あなたはテキストの類似性を評価することができる熟練の日本語話者です。2つの日本語の文章を入力として受け入れ、\"\n",
    "                \"0 から 5 までの間の数値 (小数第1位までの値) で類似度を評価します。文章の類似性が高い場合に大きい数値をとり、\"\n",
    "                \"類似性が低い場合は小さい値をとります。例えば同じ文章や完全に意味が一致している場合は5となります。\"\n",
    "                \"入力形式は文章1 : <文章1>、文章2 : <文章2> です。\"\n",
    "                \"出力はスコアの値のみです。\"\n",
    "                \"あなたの努力は素晴らしい成果をもたらすでしょう。頑張ってタスクをやり遂げてください。\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセットを構築します。データセットは、システムプロンプトの次にユーザーからの入力として2つの文が与えられ、アシスタントの応答としてその類似度のみを返却するという形式です。\n",
    "\n",
    "今回は時間短縮のためデータセット件数を100件に制約しています。\n",
    "\n",
    "整形したデータセットは、1行が1つのJSONで構成されるjsonl形式で保存します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = []\n",
    "output_file_name = 'output.jsonl'\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    user_message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"文章 1 : {row['sentence1']}, 文章 2 : {row['sentence2']}\"\n",
    "    }\n",
    "    \n",
    "    assistant_message = {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": str(row['label'])\n",
    "    }\n",
    "    \n",
    "    output_data.append({\n",
    "        \"messages\": [system_message, user_message, assistant_message]\n",
    "    })\n",
    "    \n",
    "    if index == 99:\n",
    "        break\n",
    "    \n",
    "with open(output_file_name, 'w', encoding='utf-8') as f:\n",
    "    for entry in output_data:\n",
    "        json.dump(entry, f, ensure_ascii=False)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Azure Machine Learning上で行うファインチューニングではHugging Faceのdatasetsパッケージが使用されています。以下関数の実行が通ればファインチューニングジョブでも問題なくデータセットを読み込むことができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset('json', data_files=f\"./{output_file_name}\",split='train', **{})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Azure Machine Learning上にデータセットをDataアセットとして登録する前準備として、Azure Machine Learningに接続する`MLClient`インスタンスを初期化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = os.environ.get(\"SUBSCRIPTION_ID\")\n",
    "resource_group = os.environ.get(\"RESOURCE_GROUP\")\n",
    "workspace = os.environ.get(\"AML_WORKSPACE_NAME\")\n",
    "\n",
    "ml_client = MLClient(\n",
    "    DefaultAzureCredential(), subscription_id, resource_group, workspace\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Azure Machine Learning上にデータセットをDataアセットとして登録します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuning_data = Data(\n",
    "    path=output_file_name,\n",
    "    type=AssetTypes.URI_FILE,\n",
    "    description=\"JSTSデータセットを利用したfine-tuningデータセット\",\n",
    "    name=\"semantic-text-similarity-fine-tune\",\n",
    ")\n",
    "\n",
    "ml_client.data.create_or_update(finetuning_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-ch11-env",
   "language": "python",
   "name": "py311-ch11-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
